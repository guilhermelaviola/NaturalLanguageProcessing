{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbxCohIIekozqB2J/Fm9IG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/NaturalLanguageProcessing/blob/main/Class03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Frequency**\n",
        "Word frequency analysis is a fundamental technique in natural language processing that helps computers analyze human language and supports advanced applications such as sentiment analysis, topic modeling, and text summarization. The process begins with text preprocessing, which includes normalization, removal of punctuation, special characters, and stop words to ensure accurate counting. In Python, dictionaries—particularly the Counter class—are commonly used to store and compute word frequencies efficiently. To fairly compare texts of different lengths, relative frequency is calculated by normalizing word counts by the total number of words. Interpreting frequency results requires contextual awareness, as common words may not always signal meaningful themes, and visualizations like bar charts can aid in identifying patterns and insights within the data."
      ],
      "metadata": {
        "id": "0ocmCmQnnSDl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dxlT7gs3nJzD"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries and resources:\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example: Word Counting**\n",
        "Word counting can be achieved by creating a dictionary in Python, where each word is mapped to its frequency of occurrence in the texts. This is accomplished by processing the texts to transform the content into a list of words (tokens) and then counting each word using a data structure that accumulates the frequencies."
      ],
      "metadata": {
        "id": "2D4CWsxZoXvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text example for preprocessing:\n",
        "text = ''\n",
        "\n",
        "# Splitting the sentence into words\n",
        "words = text.split()\n",
        "\n",
        "# Coounting words with Counter:\n",
        "frequencies = Counter(words)\n",
        "print(frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_LjsIlun3SI",
        "outputId": "6e35a630-6186-4630-b8b6-8626c10b589c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example: Relative Frequency**\n",
        "In the context of Natural Language Processing (NLP), relative frequency is a crucial concept for analyzing and comparing texts of different sizes and types. When examining academic and e-commerce datasets, we note that simply counting tokens can lead to biased analyses due to the disparity in the sizes of the datasets. The academic dataset, for example, has 34 million tokens, while the e-commerce dataset has approximately 3 million."
      ],
      "metadata": {
        "id": "veflD0EHosk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming we have the token count:\n",
        "academic_count = 768000\n",
        "ecommerce_count = 101000\n",
        "total_tokens_academic = 34000000\n",
        "total_tokens_ecommerce = 3000000\n",
        "\n",
        "# Calculating the relative frequency:\n",
        "freq_prop_academic = academic_count / total_tokens_academic\n",
        "freq_prop_ecommerce = ecommerce_count / total_tokens_ecommerce\n",
        "\n",
        "print(f'Relative frequency in academic: {freq_prop_academic:.4f}')\n",
        "print(f'Relative frequency in e-commerce: {freq_prop_ecommerce:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzH7_0g0ozld",
        "outputId": "828fbcca-0941-4a5c-ea41-286d0763936d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relative frequency in academic: 0.0226\n",
            "Relative frequency in e-commerce: 0.0337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example: Implementation and Visualization of Relative Frequency**\n",
        "In the practical implementation of relative frequency in Natural Language Processing (NLP), it is crucial to understand that this metric adjusts the word count to the document size, allowing for fairer comparisons between texts of different sizes. For example, comparing the word frequency between a large academic corpus and a smaller e-commerce dataset requires data normalization to avoid biased conclusions."
      ],
      "metadata": {
        "id": "2QML-AZGprU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following is a dictionary example of 'frequency_counter' with the token count and a dictionary 'token_quantity' with the total number of tokens per dataset:\n",
        "frequency_counter = {\n",
        "    'male': {'data': 100, 'analysis': 50, 'tool': 20},\n",
        "    'female': {'data': 120, 'research': 60, 'study': 30}\n",
        "}\n",
        "token_quantity = {\n",
        "    'male': 2000,\n",
        "    'female': 2500\n",
        "}\n",
        "\n",
        "relative_frequency = {}\n",
        "\n",
        "# Calculating the relative frequency for each token in each dataset:\n",
        "for gender in frequency_counter.keys():\n",
        "  relative_frequency[gender] = {}\n",
        "\n",
        "  for token in frequency_counter[gender]:\n",
        "    freq_abs = frequency_counter[gender][token]\n",
        "    total_tokens = token_quantity[gender]\n",
        "    relative_frequency[gender][token] = freq_abs / total_tokens\n",
        "\n",
        "# Displaying the results:\n",
        "for gender, tokens in relative_frequency.items():\n",
        "  print(f'Proportional frequencies for {gender}.')\n",
        "\n",
        "  for token, freq in tokens.items():\n",
        "    print(f\"{token}: {freq:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVG4i-pLoRy-",
        "outputId": "29cf5e6c-fa65-43b4-e49e-a90f0feebeb1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportional frequencies for male.\n",
            "data: 0.0500\n",
            "analysis: 0.0250\n",
            "tool: 0.0100\n",
            "Proportional frequencies for female.\n",
            "data: 0.0480\n",
            "research: 0.0240\n",
            "study: 0.0120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Interpreting Relative Frequency Results**\n",
        "Interpreting relative frequency results in Natural Language Processing (NLP) involves understanding how the values ​​reflect the linguistic and thematic characteristics of the analyzed texts. Through the analysis of the relative frequency of tokens in the datasets, it is possible to identify patterns in word usage, differences between text genres, and terms unique to each dataset."
      ],
      "metadata": {
        "id": "rR7Au02prVU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo a existência de um dicionário ‘frequencia_relativa’ para cada dataset\n",
        "sorted_tokens_male = sorted(relative_frequency['male'].items(), key=lambda item: item[1], reverse=True)\n",
        "sorted_tokens_female = sorted(relative_frequency['female'].items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# Displaying the most frequent words:\n",
        "print('Most frequent words for male:', sorted_tokens_male[:20])\n",
        "print('Most frequent words for female:', sorted_tokens_female[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjKZaqOHrdes",
        "outputId": "fb6a9e1a-1917-47be-f42c-5b94a3b6b980"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent words for male: [('data', 0.05), ('analysis', 0.025), ('tool', 0.01)]\n",
            "Most frequent words for female: [('data', 0.048), ('research', 0.024), ('study', 0.012)]\n"
          ]
        }
      ]
    }
  ]
}