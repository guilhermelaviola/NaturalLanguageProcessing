{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVNGP+EcLUottBpqO4Q2Sj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/NaturalLanguageProcessing/blob/main/ClassificationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Model**"
      ],
      "metadata": {
        "id": "Q0Wt6JQ10V0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the necessary libraries:\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy\n",
        "import random\n",
        "import string"
      ],
      "metadata": {
        "id": "rLUI7JcX0cKk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have the necessary NLTK resources downloaded:\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vxxL0Sc0hCc",
        "outputId": "a23af64e-6b06-4b21-bc2e-df873def073b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Grammatical Analysis:\n",
        "text = 'NLTK is a powerful library for processing and analyzing text data!'\n",
        "tokens = word_tokenize(text)  # Tokenization\n",
        "pos_tags = pos_tag(tokens)  # Part of speech tagging"
      ],
      "metadata": {
        "id": "djNeHW980c2x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting information:\n",
        "word_freq = FreqDist(tokens)  # Word frequency analysis\n",
        "print('Tokens:', tokens)\n",
        "print('Parts of Speech:', pos_tags)\n",
        "print('Most Common Words:', word_freq.most_common(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv6Ik-lq1aYG",
        "outputId": "6d22432e-05c4-4f29-fd44-53d72d1cf8d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'processing', 'and', 'analyzing', 'text', 'data', '!']\n",
            "Parts of Speech: [('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('powerful', 'JJ'), ('library', 'NN'), ('for', 'IN'), ('processing', 'NN'), ('and', 'CC'), ('analyzing', 'VBG'), ('text', 'JJ'), ('data', 'NN'), ('!', '.')]\n",
            "Most Common Words: [('NLTK', 1), ('is', 1), ('a', 1), ('powerful', 1), ('library', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining sample dataset:\n",
        "dataset = [\n",
        "    (\"I love this movie, it's amazing!\", 'pos'),\n",
        "    ('This film was terrible, I hated it.', 'neg'),\n",
        "    ('Absolutely fantastic experience, highly recommended!', 'pos'),\n",
        "    ('Worst movie ever, a total waste of time.', 'neg'),\n",
        "]\n"
      ],
      "metadata": {
        "id": "J2CHkK_71gJU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing (Tokenization and stopword removal):\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())  # Lowercase & tokenize\n",
        "    tokens = [word for word in tokens if word not in stop_words and word.isalnum()]  # Remove stopwords & punctuation\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "tg727siE1s8G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction woth Bag-of-words:\n",
        "def extract_features(text):\n",
        "    words = set(preprocess(text))\n",
        "    return {word: True for word in words}\n",
        "\n",
        "feature_set = [(extract_features(text), label) for (text, label) in dataset]"
      ],
      "metadata": {
        "id": "f400VFFe10Pn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a Naive Bayes Classifier:\n",
        "random.shuffle(feature_set)\n",
        "train_set = feature_set[:3]  # 75% training data\n",
        "test_set = feature_set[3:]  # 25% test data\n",
        "\n",
        "classifier = NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "9V4M1ffO17lt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy calculation:\n",
        "print('Accuracy:', accuracy(classifier, test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPV8M27H2DsK",
        "outputId": "a19d2291-854e-4d3a-a15e-a121115cec61"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision, Recall and Confusion Matrix:\n",
        "from nltk.metrics import ConfusionMatrix\n",
        "from collections import defaultdict\n",
        "\n",
        "# Get actual and predicted labels\n",
        "actual = [label for (_, label) in test_set]\n",
        "predicted = [classifier.classify(features) for (features, _) in test_set]\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "conf_matrix = ConfusionMatrix(actual, predicted)\n",
        "print('Confusion Matrix:\\n', conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ey0sOx72M_G",
        "outputId": "e983a6d8-2ab7-43cd-bfa8-fd77f620a9cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "     | n p |\n",
            "    | e o |\n",
            "    | g s |\n",
            "----+-----+\n",
            "neg |<.>. |\n",
            "pos | 1<.>|\n",
            "----+-----+\n",
            "(row = reference; col = test)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}