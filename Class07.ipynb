{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJzHkOCo3LPkGKT4hQOTOt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/NaturalLanguageProcessing/blob/main/Class07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Document Clustering & Word Clouds**\n",
        "Document clustering and word cloud techniques are important NLP methods for analyzing large amounts of text data. Document clustering groups similar documents by representing them as numerical vectors, often using the Bag of Words model and measuring similarity with metrics like cosine distance, making it especially useful in recommendation systems to suggest content with similar themes. Word clouds, in contrast, visually display word frequency, highlighting prominent terms through size differences to quickly reveal key themes and trends. Creating word clouds involves tokenization, removing stop words, and counting word frequencies, often with the help of Python libraries. Together, these techniques help organize, interpret, and extract meaningful insights from textual data in applications such as text mining, sentiment analysis, and recommendation systems."
      ],
      "metadata": {
        "id": "Q0Wt6JQ10V0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the necessary libraries and resources:\n",
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "T2Fll3S5NiPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset:\n",
        "df = pd.read_csv('dataset_movies.csv')\n",
        "\n",
        "# Assuming 'df' has a 'tokens' column with tokenized tokens, then we can count the frequency of the tokens:\n",
        "def count_frequency(tokens):\n",
        "    frequencies = {}\n",
        "    for token in tokens:\n",
        "        if token in frequencies:\n",
        "            frequencies[token] += 1\n",
        "        else:\n",
        "            frequencies[token] = 1\n",
        "    return frequencies\n",
        "\n",
        "# Generating a Word Cloud for each cluster:\n",
        "for cluster in clusters:\n",
        "    tokens_cluster = []\n",
        "    for movie in cluster:\n",
        "        tokens_cluster.extend(df.loc[movie, 'tokens'])\n",
        "    frequencies = count_frequency(tokens_cluster)\n",
        "    wordcloud = WordCloud(background_color='white').generate_from_frequencies(frequencies)\n",
        "\n",
        "    # Displaying the Word Cloud:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(“off”)\n",
        "    plt.title(f'Cluster Word Cloud {cluster[0]}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lr7xhrGIN2QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing the dataset:\n",
        "dataset = pd.read_csv('https://github.com/alvelvis/data-movies-willianoliveiragibin/raw/main/data-willianoliveiragibin.csv', index_col=0)\n",
        "dataset\n",
        "dataset.Description\n",
        "type(dataset.Description[0])\n",
        "dataset.Description = dataset.Description.apply(eval)\n",
        "type(dataset.Description[0])\n",
        "dataset.Description = dataset.Description.apply(lambda x: ''.join(x))\n",
        "dataset.Description"
      ],
      "metadata": {
        "id": "rLUI7JcX0cKk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "634d164c-adba-4cbc-f8ec-fc2718f31e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Overthecourseofseveralyears,twoconvictsformafr...\n",
              "1       DonVitoCorleone,headofamafiafamily,decidestoha...\n",
              "2       AnanimeadaptationoftheHinduepictheRamayana,whe...\n",
              "3       Lazy,uneducatedstudentsshareaveryclosebond.The...\n",
              "4       WhenthemenaceknownastheJokerwreakshavocandchao...\n",
              "                              ...                        \n",
              "9995    Thegangencounterswithsomespiritualbodiesandfin...\n",
              "9996    Afteralifetimeofscams,aself-centeredmillennial...\n",
              "9997    Afatherdoesn'twanthisthreedaughterstogetmarrie...\n",
              "9998    Anintimaterelationshipbetweenahumanandanandroi...\n",
              "9999    Withtheworld'sendimminent,adyingmothersendsher...\n",
              "Name: Description, Length: 10000, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Overthecourseofseveralyears,twoconvictsformafr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DonVitoCorleone,headofamafiafamily,decidestoha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AnanimeadaptationoftheHinduepictheRamayana,whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lazy,uneducatedstudentsshareaveryclosebond.The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WhenthemenaceknownastheJokerwreakshavocandchao...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Thegangencounterswithsomespiritualbodiesandfin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Afteralifetimeofscams,aself-centeredmillennial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Afatherdoesn'twanthisthreedaughterstogetmarrie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Anintimaterelationshipbetweenahumanandanandroi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Withtheworld'sendimminent,adyingmothersendsher...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting tokens off the dataset:\n",
        "import string\n",
        "punctuation = string.punctuation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def extract_tokens(text):\n",
        "  freq = {}\n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [token.lower() for token in tokens if token not in punctuation and token.lower() not in stopwords]\n",
        "  return tokens\n",
        "\n",
        "  dataset['tokens'] = dataset.Description.apply(extract_tokens)\n",
        "\n",
        "  dataset.tokens[0]\n",
        "\n",
        "\n",
        "  all_the_tokens = []\n",
        "\n",
        "  for tokens in dataset.tokens:\n",
        "    all_the_tokens.extend(tokens)\n",
        "    print(len(all_the_tokens))\n",
        "    print(len(set(all_the_tokens)))\n",
        "    freq_tokens = {}\n",
        "    for token in all_the_tokens:\n",
        "      if not token in freq_tokens:\n",
        "        freq_tokens[token] = 0\n",
        "        freq_tokens[token] += 1\n",
        "        most_frequent_tokens = sorted(freq_tokens.items(), key=lambda x: -x[1])[:1000]\n",
        "        most_frequest_tokens\n",
        "        most_frequest_tokens = [x[0] for x in most_frequest_tokens]\n",
        "        print(most_frequest_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7itNUwg2IpE_",
        "outputId": "a7d4a8a9-7377-4e93-d66e-cf415c208c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing all the movie descriptions:\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def vectorize(tokens):\n",
        "  vector = []\n",
        "  for token in most_frequent_tokens:\n",
        "    vector.append(tokens.count(token))\n",
        "    return np.asarray(vector)\n",
        "\n",
        "    first_movie = dataset.tokens[0]\n",
        "\n",
        "    first_movie_vector = vectorize(first_movie)\n",
        "\n",
        "    print(first_movie_vector)\n",
        "\n",
        "    print(len(first_movie_vector))\n",
        "\n",
        "    dataset['vector'] = dataset['tokens'].apply(vectorize)\n",
        "    dataset.vectors"
      ],
      "metadata": {
        "id": "GeeMS0w4KwWe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}