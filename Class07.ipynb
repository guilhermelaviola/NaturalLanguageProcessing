{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/I42cPdYeOw056TD07nme",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/NaturalLanguageProcessing/blob/main/Class07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Grouping documents and word cloud**"
      ],
      "metadata": {
        "id": "Q0Wt6JQ10V0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing the dataset:\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('https://github.com/alvelvis/data-movies-willianoliveiragibin/raw/main/data-willianoliveiragibin.csv', index_col=0)\n",
        "dataset\n",
        "dataset.Description\n",
        "type(dataset.Description[0])\n",
        "dataset.Description = dataset.Description.apply(eval)\n",
        "type(dataset.Description[0])\n",
        "dataset.Description = dataset.Description.apply(lambda x: ''.join(x))\n",
        "dataset.Description"
      ],
      "metadata": {
        "id": "rLUI7JcX0cKk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "634d164c-adba-4cbc-f8ec-fc2718f31e9b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Overthecourseofseveralyears,twoconvictsformafr...\n",
              "1       DonVitoCorleone,headofamafiafamily,decidestoha...\n",
              "2       AnanimeadaptationoftheHinduepictheRamayana,whe...\n",
              "3       Lazy,uneducatedstudentsshareaveryclosebond.The...\n",
              "4       WhenthemenaceknownastheJokerwreakshavocandchao...\n",
              "                              ...                        \n",
              "9995    Thegangencounterswithsomespiritualbodiesandfin...\n",
              "9996    Afteralifetimeofscams,aself-centeredmillennial...\n",
              "9997    Afatherdoesn'twanthisthreedaughterstogetmarrie...\n",
              "9998    Anintimaterelationshipbetweenahumanandanandroi...\n",
              "9999    Withtheworld'sendimminent,adyingmothersendsher...\n",
              "Name: Description, Length: 10000, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Overthecourseofseveralyears,twoconvictsformafr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DonVitoCorleone,headofamafiafamily,decidestoha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AnanimeadaptationoftheHinduepictheRamayana,whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lazy,uneducatedstudentsshareaveryclosebond.The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WhenthemenaceknownastheJokerwreakshavocandchao...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Thegangencounterswithsomespiritualbodiesandfin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Afteralifetimeofscams,aself-centeredmillennial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Afatherdoesn'twanthisthreedaughterstogetmarrie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Anintimaterelationshipbetweenahumanandanandroi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Withtheworld'sendimminent,adyingmothersendsher...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting tokens off the dataset:\n",
        "import string\n",
        "punctuation = string.punctuation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def extract_tokens(text):\n",
        "  freq = {}\n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [token.lower() for token in tokens if token not in punctuation and token.lower() not in stopwords]\n",
        "  return tokens\n",
        "\n",
        "  dataset['tokens'] = dataset.Description.apply(extract_tokens)\n",
        "\n",
        "  dataset.tokens[0]\n",
        "\n",
        "\n",
        "  all_the_tokens = []\n",
        "\n",
        "  for tokens in dataset.tokens:\n",
        "    all_the_tokens.extend(tokens)\n",
        "    print(len(all_the_tokens))\n",
        "    print(len(set(all_the_tokens)))\n",
        "    freq_tokens = {}\n",
        "    for token in all_the_tokens:\n",
        "      if not token in freq_tokens:\n",
        "        freq_tokens[token] = 0\n",
        "        freq_tokens[token] += 1\n",
        "        most_frequent_tokens = sorted(freq_tokens.items(), key=lambda x: -x[1])[:1000]\n",
        "        most_frequest_tokens\n",
        "        most_frequest_tokens = [x[0] for x in most_frequest_tokens]\n",
        "        print(most_frequest_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7itNUwg2IpE_",
        "outputId": "a7d4a8a9-7377-4e93-d66e-cf415c208c22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing all the movie descriptions:\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def vectorize(tokens):\n",
        "  vector = []\n",
        "  for token in most_frequent_tokens:\n",
        "    vector.append(tokens.count(token))\n",
        "    return np.asarray(vector)\n",
        "\n",
        "    first_movie = dataset.tokens[0]\n",
        "\n",
        "    first_movie_vector = vectorize(first_movie)\n",
        "\n",
        "    print(first_movie_vector)\n",
        "\n",
        "    print(len(first_movie_vector))\n",
        "\n",
        "    dataset['vector'] = dataset['tokens'].apply(vectorize)\n",
        "    dataset.vectors"
      ],
      "metadata": {
        "id": "GeeMS0w4KwWe"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}